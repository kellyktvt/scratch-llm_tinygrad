{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ONNX model in tinygrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from tg_onnx import get_run_onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load(\"shakespeare_model.onnx\")\n",
    "# Create a callable object 'run_onnx' that executes the model\n",
    "run_onnx = get_run_onnx(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------+------------+\n",
      "|                   Modules                    | Parameters |\n",
      "+----------------------------------------------+------------+\n",
      "|            token_embedding.weight            |  1048576   |\n",
      "|         transformer.0.norm_attn.gain         |    256     |\n",
      "| transformer.0.multihead_attn.proj_qkv.weight |   196608   |\n",
      "| transformer.0.multihead_attn.proj_out.weight |   65536    |\n",
      "|         transformer.0.norm_ffn.gain          |    256     |\n",
      "|     transformer.0.feed_forward.0.weight      |   262144   |\n",
      "|  transformer.0.feed_forward.1.linear.weight  |  2097152   |\n",
      "|   transformer.0.feed_forward.1.linear.bias   |    2048    |\n",
      "|     transformer.0.feed_forward.2.weight      |   262144   |\n",
      "|         transformer.1.norm_attn.gain         |    256     |\n",
      "| transformer.1.multihead_attn.proj_qkv.weight |   196608   |\n",
      "| transformer.1.multihead_attn.proj_out.weight |   65536    |\n",
      "|         transformer.1.norm_ffn.gain          |    256     |\n",
      "|     transformer.1.feed_forward.0.weight      |   262144   |\n",
      "|  transformer.1.feed_forward.1.linear.weight  |  2097152   |\n",
      "|   transformer.1.feed_forward.1.linear.bias   |    2048    |\n",
      "|     transformer.1.feed_forward.2.weight      |   262144   |\n",
      "|         transformer.2.norm_attn.gain         |    256     |\n",
      "| transformer.2.multihead_attn.proj_qkv.weight |   196608   |\n",
      "| transformer.2.multihead_attn.proj_out.weight |   65536    |\n",
      "|         transformer.2.norm_ffn.gain          |    256     |\n",
      "|     transformer.2.feed_forward.0.weight      |   262144   |\n",
      "|  transformer.2.feed_forward.1.linear.weight  |  2097152   |\n",
      "|   transformer.2.feed_forward.1.linear.bias   |    2048    |\n",
      "|     transformer.2.feed_forward.2.weight      |   262144   |\n",
      "|         transformer.3.norm_attn.gain         |    256     |\n",
      "| transformer.3.multihead_attn.proj_qkv.weight |   196608   |\n",
      "| transformer.3.multihead_attn.proj_out.weight |   65536    |\n",
      "|         transformer.3.norm_ffn.gain          |    256     |\n",
      "|     transformer.3.feed_forward.0.weight      |   262144   |\n",
      "|  transformer.3.feed_forward.1.linear.weight  |  2097152   |\n",
      "|   transformer.3.feed_forward.1.linear.bias   |    2048    |\n",
      "|     transformer.3.feed_forward.2.weight      |   262144   |\n",
      "|                  norm.gain                   |    256     |\n",
      "|             projection_head.bias             |    4096    |\n",
      "+----------------------------------------------+------------+\n",
      "Total Trainable Params: 12597504\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(12597504)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "import numpy as np\n",
    "import onnx\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "\n",
    "    name_mapping = {\n",
    "        \"token_embedding.weight\": \"token_embedding.weight\",\n",
    "        \"onnx::Mul_610\": \"transformer.0.norm_attn.gain\",\n",
    "        \"onnx::MatMul_611\": \"transformer.0.multihead_attn.proj_qkv.weight\",\n",
    "        \"onnx::MatMul_631\": \"transformer.0.multihead_attn.proj_out.weight\",\n",
    "        \"onnx::Mul_632\": \"transformer.0.norm_ffn.gain\",\n",
    "        \"onnx::MatMul_633\": \"transformer.0.feed_forward.0.weight\",\n",
    "        \"onnx::MatMul_634\": \"transformer.0.feed_forward.1.linear.weight\",\n",
    "        \"transformer.0.feed_forward.1.linear.bias\": \"transformer.0.feed_forward.1.linear.bias\",\n",
    "        \"onnx::MatMul_643\": \"transformer.0.feed_forward.2.weight\",\n",
    "        \"onnx::Mul_644\": \"transformer.1.norm_attn.gain\",\n",
    "        \"onnx::MatMul_645\": \"transformer.1.multihead_attn.proj_qkv.weight\",\n",
    "        \"onnx::MatMul_665\": \"transformer.1.multihead_attn.proj_out.weight\",\n",
    "        \"onnx::Mul_666\": \"transformer.1.norm_ffn.gain\",\n",
    "        \"onnx::MatMul_667\": \"transformer.1.feed_forward.0.weight\",\n",
    "        \"onnx::MatMul_668\": \"transformer.1.feed_forward.1.linear.weight\",\n",
    "        \"transformer.1.feed_forward.1.linear.bias\": \"transformer.1.feed_forward.1.linear.bias\",\n",
    "        \"onnx::MatMul_677\": \"transformer.1.feed_forward.2.weight\",\n",
    "        \"onnx::Mul_678\": \"transformer.2.norm_attn.gain\",\n",
    "        \"onnx::MatMul_679\": \"transformer.2.multihead_attn.proj_qkv.weight\",\n",
    "        \"onnx::MatMul_699\": \"transformer.2.multihead_attn.proj_out.weight\",\n",
    "        \"onnx::Mul_700\": \"transformer.2.norm_ffn.gain\",\n",
    "        \"onnx::MatMul_701\": \"transformer.2.feed_forward.0.weight\",\n",
    "        \"onnx::MatMul_702\": \"transformer.2.feed_forward.1.linear.weight\",\n",
    "        \"transformer.2.feed_forward.1.linear.bias\": \"transformer.2.feed_forward.1.linear.bias\",\n",
    "        \"onnx::MatMul_711\": \"transformer.2.feed_forward.2.weight\",\n",
    "        \"onnx::Mul_712\": \"transformer.3.norm_attn.gain\",\n",
    "        \"onnx::MatMul_713\": \"transformer.3.multihead_attn.proj_qkv.weight\",\n",
    "        \"onnx::MatMul_733\": \"transformer.3.multihead_attn.proj_out.weight\",\n",
    "        \"onnx::Mul_734\": \"transformer.3.norm_ffn.gain\",\n",
    "        \"onnx::MatMul_735\": \"transformer.3.feed_forward.0.weight\",\n",
    "        \"onnx::MatMul_736\": \"transformer.3.feed_forward.1.linear.weight\",\n",
    "        \"transformer.3.feed_forward.1.linear.bias\": \"transformer.3.feed_forward.1.linear.bias\",\n",
    "        \"onnx::MatMul_745\": \"transformer.3.feed_forward.2.weight\",\n",
    "        \"onnx::Mul_746\": \"norm.gain\",\n",
    "        \"projection_head.bias\": \"projection_head.bias\",\n",
    "    }\n",
    "\n",
    "    exclude_params = [\n",
    "        \"onnx::MatMul_747\",\n",
    "        \"transformer.0.multihead_attn.positional_encoding.position_cos\",\n",
    "        \"transformer.0.multihead_attn.positional_encoding.position_sin\",\n",
    "        \"onnx::Where_630\"\n",
    "    ]\n",
    "\n",
    "    module_order = [\n",
    "        \"token_embedding.weight\",\n",
    "        \"transformer.0.norm_attn.gain\",\n",
    "        \"transformer.0.multihead_attn.proj_qkv.weight\",\n",
    "        \"transformer.0.multihead_attn.proj_out.weight\",\n",
    "        \"transformer.0.norm_ffn.gain\",\n",
    "        \"transformer.0.feed_forward.0.weight\",\n",
    "        \"transformer.0.feed_forward.1.linear.weight\",\n",
    "        \"transformer.0.feed_forward.1.linear.bias\",\n",
    "        \"transformer.0.feed_forward.2.weight\",\n",
    "        \"transformer.1.norm_attn.gain\",\n",
    "        \"transformer.1.multihead_attn.proj_qkv.weight\",\n",
    "        \"transformer.1.multihead_attn.proj_out.weight\",\n",
    "        \"transformer.1.norm_ffn.gain\",\n",
    "        \"transformer.1.feed_forward.0.weight\",\n",
    "        \"transformer.1.feed_forward.1.linear.weight\",\n",
    "        \"transformer.1.feed_forward.1.linear.bias\",\n",
    "        \"transformer.1.feed_forward.2.weight\",\n",
    "        \"transformer.2.norm_attn.gain\",\n",
    "        \"transformer.2.multihead_attn.proj_qkv.weight\",\n",
    "        \"transformer.2.multihead_attn.proj_out.weight\",\n",
    "        \"transformer.2.norm_ffn.gain\",\n",
    "        \"transformer.2.feed_forward.0.weight\",\n",
    "        \"transformer.2.feed_forward.1.linear.weight\",\n",
    "        \"transformer.2.feed_forward.1.linear.bias\",\n",
    "        \"transformer.2.feed_forward.2.weight\",\n",
    "        \"transformer.3.norm_attn.gain\",\n",
    "        \"transformer.3.multihead_attn.proj_qkv.weight\",\n",
    "        \"transformer.3.multihead_attn.proj_out.weight\",\n",
    "        \"transformer.3.norm_ffn.gain\",\n",
    "        \"transformer.3.feed_forward.0.weight\",\n",
    "        \"transformer.3.feed_forward.1.linear.weight\",\n",
    "        \"transformer.3.feed_forward.1.linear.bias\",\n",
    "        \"transformer.3.feed_forward.2.weight\",\n",
    "        \"norm.gain\",\n",
    "        \"projection_head.bias\"\n",
    "    ]\n",
    "\n",
    "    params_dict = {}\n",
    "\n",
    "    for initializer in model.graph.initializer:\n",
    "        name = initializer.name\n",
    "        params = np.prod(initializer.dims)\n",
    "        mapped_name = name_mapping.get(name, name)\n",
    "        if mapped_name not in exclude_params:\n",
    "            params_dict[mapped_name] = params\n",
    "            total_params += params\n",
    "\n",
    "    for module in module_order:\n",
    "        if module in params_dict:\n",
    "            table.add_row([module, params_dict[module]])\n",
    "\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\\n\")\n",
    "    return total_params\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load(\"shakespeare_model.onnx\")\n",
    "\n",
    "# Call the function\n",
    "count_parameters(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare tokenizer and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from pathlib import Path\n",
    "from model.tokenizer import Tokenizer\n",
    "\n",
    "# specifies path to input text file used for training or retraining tokenizer\n",
    "input_file = \"../data/shakespeare/tinyshakespeare.txt\"\n",
    "# creates new file path for tokenizer model by changing suffix of input file\n",
    "output_file = Path(input_file).with_suffix(\".model\")\n",
    "# initialize tokenizer by loading it from 'output_file'\n",
    "tokenizer = Tokenizer(str(output_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Before', '▁we', '▁proceed', '▁any', '▁further', ',', '▁hear', '▁me', '▁speak', '.']\n"
     ]
    }
   ],
   "source": [
    "# Test tokenizer functionality\n",
    "sentence = \"Before we proceed any further, hear me speak.\"\n",
    "print(tokenizer.sp.EncodeAsPieces(sentence))\n",
    "\n",
    "# Ensure encoding and decoding returns the original sentence\n",
    "assert tokenizer.decode(tokenizer.encode(sentence)) == sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "generate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m inputs \u001b[38;5;241m=\u001b[39m Tensor(prompt, dtype\u001b[38;5;241m=\u001b[39mdtypes\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Generate a sequence of tokens using the LLM model starting from the 'inputs'\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m(inputs, max_seq_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Convert the output tensor to a list of integers\u001b[39;00m\n\u001b[1;32m     19\u001b[0m output_list \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[0;31mAttributeError\u001b[0m: generate"
     ]
    }
   ],
   "source": [
    "from tinygrad.tensor import Tensor, dtypes\n",
    "from model.llm import sample_top_p, LLM\n",
    "\n",
    "# Encode the prompt using the tokenizer\n",
    "prompt = tokenizer.encode(\n",
    "    \"KING HENRY VI:\",\n",
    "    beg_of_string=True,\n",
    "    pad_seq=True,\n",
    "    seq_len=llm_config.seq_len,\n",
    ")\n",
    "\n",
    "# Convert the encoded prompt to a tinygrad tensor and add an extra dimension\n",
    "inputs = Tensor(prompt, dtype=dtypes.int32).unsqueeze(0)\n",
    "\n",
    "# Generate a sequence of tokens using the LLM model starting from the 'inputs'\n",
    "out = model.generate(inputs, max_seq_len=64)\n",
    "\n",
    "# Convert the output tensor to a list of integers\n",
    "output_list = out.flatten().astype(int).tolist()\n",
    "\n",
    "# Decode the generated sequence of token IDs back into a human-readable string\n",
    "decoded_output = tokenizer.decode(output_list)\n",
    "print(decoded_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
